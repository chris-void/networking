# CS655 scheduler simulation design #

This document contains a description of the design of the CS655 packet traffic
simulation.

This README file is written in the markup language "[Markdown][1]".

Jeffrey Finkelstein <jeffreyf@bu.edu>
October 2011

[1]: http://daringfireball.net/projects/markdown

## Pipeline setup ##

The scheduler implementations (first-in first-out, round-robin, and deficit
round-robin) provide a queue interface (enqueue and dequeue functions) to the
traffic sources and traffic sink. The scheduler is generic, so it can enqueue
or dequeue object with an owner (a user ID number) and a length.

This simulation includes eleven traffic sources (four telnet sources, six FTP
sources, and one rogue source) and one traffic sink. The traffic sources
generate packets of variable lengths and enqueue their packets, once created,
on an intermediate scheduler object. The traffic sink continually attempts to
dequeue a packet from the scheduler object.

A traffic source continuously generates a sequence of packets. While the packet
is being generated, the traffic source waits for the correct amount of time
(which depends on the length of the packet, in bits). Once the packet has been
generated, it is enqueued on the scheduler, then the process repeats. This
continues until a maximum number of packets have been generated by all traffic
sources.

The traffic sink continuously dequeues a sequence of packets from the
scheduler. While the packet is being processed, the traffic sink waits for the
correct amount of time (which depends on the length of the packet, in
bits). Once the packet has been processed by the traffic sink, the process
repeats. This continues until all packets have been dequeued from the
scheduler.

The scheduler implementations can be found in the `simulation.schedulers`
module, and the traffic source and traffic sink classes can be found in the
`simulation.endpoints` module.

## Simulation library ##

This simulation uses the [SimPy][2] discrete event simulation library to
maintain the bookkeeping for the simulation. Each traffic source and traffic
sink is a SimPy `Process` object, which is the basic actor in a SimPy
simulation. The main technique used to schedule events is the

    yield hold, self, time

statement, which allows a `Process` to suspend execution for the specified
amount of time (`hold` just instructs the simulation framework that this
process will be put on hold for some amount of time, and `self` is a reference
to the current `Process`). In the traffic source, this is used to wait for all
the bits of a packet to be generated. In the traffic sink, this is used to wait
for all the bits of a packet to be processed once dequeued from the scheduler,
and also to wait until there are packets to dequeue from the scheduler if it is
empty at any point.

The only other SimPy technique used is the `Monitor`, which monitors some
scalar as it depends on time during the simulation. The traffic sink uses a
`Monitor` when a packet is dequeued to record the latency for that packet, and
the scheduler uses one whenever a packet is enqueued or dequeued to record the
length of the queue (although this data is not currently used in the
statistical analysis of the simulation).

[2]: http://simpy.sourceforge.net

## Statistics collection ##

A packet's arrival time on the scheduler is recorded by the traffic source
which generated it, and the time at which it is first processed is recorded by
the traffic sink. The latency for that packet, the difference between the time
of processing and the time of arrival, is then observed by a SimPy `Monitor` on
the traffic sink. See the `simulation.analysis.mean_latency()` function.

Each traffic source records the time of the first arrival on the scheduler of
any packet owned by that traffic source. The traffic sink records the time of
the transmission of the final packet by each of the sources. The measured
throughput of a traffic source, the number of bits sent over the total time
that bits owned by that traffic source are in the pipeline, is then computed
after the simulation has completed. See the
`simulation.analysis.measured_throughput()` function.

The data, collected after a simulation, for a particular source (or more
accurately, a source/sink pipeline) is encapsulated in the
`simulation.analysis.PipelineStatistics` class. 

After performing a certain number of trials, the `experiments.py` script writes
lines of data like this:

    # sched load ID trial_num throughput_diff throughput_ratio mean_latency
    FIFO 0.4 0 0 -0.275687400307 0.241859649157 34458519.2273
    RR 0.8 3 72 -0.633664484088 0.128711334378 55184766.3237
    DRR 2.0 2 62 -1.72082572934 0.0535458488628 40349094.5481
    ...

where `sched` is the name of the scheduler used in that trial, `load` is the
total offered load used in that trial, `ID` is the ID number of the traffic
source for which this line is a record, `trial_num` identifies the number of
the trial run with the preceding parameters, `throughput_diff` is the
difference between the expected throughput and the measured throughput (in bit
per second), `throughput_ratio` is the ratio of expected throughput to measured
throughput (in bits per second), and `mean_latency` is the mean latency of all
packets sent by the current traffic source in this trial.

## Performing trials ##

The `simulation.runner.run_parameterized_simulation` function performs a single
trial of the simulation with a specific set of parameters, including scheduler
type, maximum number of packets to send, total offered load, number of traffic
sources of each type, etc. It returns a mapping from traffic source ID number
to `simulation.analysis.PipelineStatistics` object representing the data
collected during and after the simulation for that traffic source.

A single parameterized simulation can also be performed from the command-line
by running:

    python simulation -c FIFO -m 0.4

This will print out some statistics for each traffic source to `stdout`.

The `experiments.py` script performs the specific experiments described in the
assignment, and writes the output (as described in the previous section) to
either `stdout` or a file specified by name as a command-line argument.

## Analysis and plotting ##

The `plot.py` script accepts input in the format specified in the "Statistics
collection" section. It computes the averages over all trials for throughputs
and latencies, along with the corresponding confidence intervals, and plots
them using the Python plotting library `matplotlib`.
